pandas中dataframe的查询方法
一、[]切片方法
使用[]对dataframe进行切片
eg:行选择：
data[1:5]选择行标为1到4的的四行
列选择：
data[['rnd_1','rnd_3']]选择列标签为rnd_1和rnd_3的两列
二、loc
loc可以按索引进行行列选择,loc与第一种方法不同会把第五行也算进去。
data.loc[1:5]选择索引为1到5 的五行
data.loc[2:4,['rnd_2','fecha']]选择索引为2到4三行，列索引为'rnd_2','fecha'两列
三、iloc
iloc按照索引的位置来取。索引是从0开始，类似于数组。
切片选择
data.iloc[[1,12,34],[0,2]]选择第1,12,34行的0,2列
其中访问单个元素的方法还有at\iat\ix

one-hot编码在机器学习中的使用
一、什么是onehot编码
one-hot编码，又称一位有效编码，主要是采用N位寄存器来对N个状态进行编码，
每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。
one-hot编码是分类变量作为二进制向量的表示。这首先要求将分类映射到整数值，然后
每个整数值表示为二进制向量，除了整数索引之外，它都是零值，它被标记为1。
二、one-hot编码使用目的
1、将离散特征的取值范围扩展到欧式空间。
2、将离散型特征使用one-hot编码，可以会让特征之间的距离计算更加合理。
将离散特征通过one-hot编码映射到欧式空间，是因为，在回归，分类，聚类等机器学习算法中，
特征之间距离的计算或相似度的计算是非常重要的，而我们常用的距离或相似度的计算都是在欧式
空间的相似度计算，计算余弦相似性，基于的就是欧式空间。
3、基于树的方法是不需要进行特征归一化，例如随机森林，bagging和boosting
三、one-hot编码规则
假如有三种颜色特征：红、黄、蓝。 在利用机器学习的算法时一般需要进行向量化或者数字化。
那么你可能想令 红=1，黄=2，蓝=3. 那么这样其实实现了标签编码，即给不同类别以标签。
然而这意味着机器可能会学习到“红<黄<蓝”，但这并不是我们的让机器学习的本意，只是想让机器区分它们，
并无大小比较之意。所以这时标签编码是不够的，需要进一步转换。因为有三种颜色状态，所以就有3个比特。
即红色：1 0 0 ，黄色: 0 1 0，蓝色：0 0 1 。如此一来每两个向量之间的距离都是根号2，在向量空间距离都
相等，所以这样不会出现偏序性，基本不会影响基于向量空间度量算法的效果。
四、OneHotEncoder（）的参数的意思
n_valuese，表示每个特征使用几维的数值由数据集自动推断，即几种类别就使用几位来表示。
categorical_features ，这个参数指定了对哪些特征进行编码，默认对所有类别都进行编码。
dtype=<class ‘numpy.float64’> 表示编码数值格式，默认是浮点型。
sparse=True 表示编码的格式，默认为 True，即为稀疏的格式，指定 False 则就不用 toarray() 了
handle_unknown=’error’，其值可以指定为 "error" 或者 "ignore"，即如果碰到未知的类别，是返回一个错误还是忽略它。
standardscale特征标准化
归一化和标准化都快被叫烂了，很多时候我们都认为二者有相同的意思。粗略上是可以这样认为的，功能是一样的，目的都是消除量纲的影响，以解决指标之间的可比性问题。
standardscale采用z-score标准化



